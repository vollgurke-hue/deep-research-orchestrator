{
  "model_id": "llama-3-1-8b-instruct",
  "display_name": "Llama 3.1 8B Instruct",
  "provider": "ollama",
  "model_path": "llama3.1:8b-instruct-q4_K_M",
  "capabilities": ["extraction", "reasoning"],
  "quality_level": "fast",
  "vram_mb": 5500,
  "ram_mb": 2000,
  "context_window": 8192,
  "quantization": "Q4_K_M",
  "parameters": {
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "repeat_penalty": 1.1,
    "num_gpu_layers": -1,
    "n_ctx": 8192,
    "n_batch": 512
  },
  "enabled": true,
  "metadata": {
    "architecture": "llama",
    "base_model": "Meta Llama 3.1",
    "license": "Llama 3.1 Community License",
    "created_at": "2026-01-08T17:00:00Z"
  }
}
