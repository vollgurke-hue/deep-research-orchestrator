# Gemini Review Results - SRO Implementation

**Review Date:** 2026-01-15
**Reviewer:** Gemini Advanced
**Dokumente:** 9 Konzept-Dateien + Implementation Analysis
**Status:** ‚úÖ Approved mit Design-Entscheidungen

---

## Executive Summary

Gemini hat das SRO-Konzept reviewed und als **technisch korrekt und umsetzbar** best√§tigt. Die bestehende Code-Basis (70% Logik-Ebene implementiert) erm√∂glicht eine **evolution√§re Migration** statt Neuschreibung.

**Haupterkenntnis:** SPO-Extraktion muss in Cluster 1 (nicht Cluster 2) vorgezogen werden, da ohne strukturierte Tripletts der MCTS-Motor kein strukturiertes "Futter" hat.

---

## 1. Strategischer Review

### ‚úÖ Technisches Verst√§ndnis & Koh√§renz

**Gemini-Zitat:**
> "Das Zusammenspiel zwischen **epistemischem MCTS** (Suche nach Erkenntnis) und dem **Perspektiven-Graphen** (Bias-Mapping) ist das Herzst√ºck. Die Erkenntnis, dass Bias eine *Information* ist, hebt das System weit √ºber herk√∂mmliche RAG-Systeme hinaus."

**Best√§tigung:**
- ‚úÖ Inference-time Compute Scaling ist f√ºr lokale Hardware optimal
- ‚úÖ RLAIF + Abliterated Models Strategie ist korrekt
- ‚úÖ Drei-Ebenen-Architektur (Kontrolle/Logik/Wissen) ist koh√§rent
- ‚úÖ Bias-as-Information Paradigma ist technisch fundiert

---

### ‚ö†Ô∏è Was fehlt noch?

Gemini identifizierte 2 zus√§tzliche Komponenten:

#### 1. Conflict Resolution Strategy
**Problem:** Wenn zwei hoch-verifizierte Pfade zu gegens√§tzlichen Handlungsanweisungen f√ºhren, braucht MCTS eine "Tie-Breaker"-Logik.

**L√∂sung:** Gewichtete Axiom-Hierarchie
```python
class AxiomHierarchy:
    """
    Aufl√∂sung von Axiom-Konflikten durch Priorit√§ts-Hierarchie.

    Beispiel: "Sicherheit schl√§gt Rendite"
    - Axiom "risk_management" (priority: critical) > "opportunity_cost" (priority: high)
    """
    def resolve_conflict(
        self,
        path_a: List[str],
        path_b: List[str],
        axiom_scores_a: Dict[str, float],
        axiom_scores_b: Dict[str, float]
    ) -> str:
        """Returns winning path ID based on axiom priorities."""
        pass
```

**Implementation:** Cluster 2 (Axiom Judge erweitern)

---

#### 2. Token-Budget-Manager
**Problem:** MCTS/RLM k√∂nnten endlos laufen und Token verschwenden in unwichtigen √Ñsten.

**L√∂sung:** Node-spezifisches Token-Limit
```python
class TokenBudgetManager:
    """
    Verhindert "Ewigkeitsschleifen" in MCTS-√Ñsten.

    - Gesamtbudget pro Session (z.B. 500k Tokens)
    - Node-Budget basierend auf UCB1-Score (wichtige Nodes bekommen mehr)
    - Automatisches Pruning bei Budget-√úberschreitung
    """
    def allocate_budget(self, node: ToTNode, total_budget: int) -> int:
        """Dynamische Budget-Zuteilung basierend auf Node-Wichtigkeit."""
        pass
```

**Implementation:** Cluster 1 (MCTS erweitern)

---

### ‚úÖ Keine Widerspr√ºche

**Gemini-Zitat:**
> "Bisher keine gravierenden Widerspr√ºche. Die Kl√§rung zwischen **RLAIF (Inference-time)** und **Abliterated Models** wurde sauber gel√∂st: Wir nutzen die Freiheit des Modells, um es dann durch ein externes 'Kritiker-Modell' (AxiomJudge) streng zu bewerten."

---

### üîÑ Implementierungs-Reihenfolge Anpassung

**Original Plan (MASTER_IMPLEMENTATION_PROMPT):**
```
Cluster 1: RLM + XoT
Cluster 2: SPO + Tiered RAG  ‚Üê SPO war hier
Cluster 3: BiasVector
Cluster 4: Epistemic MCTS
Cluster 5: Privacy
```

**Gemini-Empfehlung:**
```
Cluster 1: SPO + XoT + MCTS Token Budget  ‚Üê SPO vorgezogen!
Cluster 2: Tiered RAG + Axiom Judge + Conflict Resolution
Cluster 3: BiasVector + Perspektiven-Graph
Cluster 4: RLM + Epistemic MCTS  ‚Üê RLM verschoben
Cluster 5: Privacy (nur wenn Cloud genutzt wird)
```

**Begr√ºndung:**
> "Ohne strukturierte Fakten (Tripletts) ist der 'Motor' (MCTS) zwar stark, hat aber kein strukturiertes 'Futter' zum Verarbeiten."

---

## 2. Design-Entscheidungen (Offene Fragen beantwortet)

### Frage 1: SPO-Extraktion Storage

**Options:**
- A) Neo4j (dedizierte Graph-Datenbank)
- B) SQLite mit Graph-Wrapper
- C) NetworkX in-memory mit Serialization

**Gemini-Entscheidung: Option B (SQLite)**

**Begr√ºndung:**
> "Neo4j ist f√ºr ein lokales, souver√§nes System zu schwerf√§llig. SQLite ist portabel, extrem performant f√ºr sequentielle Prozesse und bietet mit `json1`-Extensions oder einfachen Adjazenzlisten genug Graph-Power."

**Implementation:**
```python
# SPO-Tripletts in SQLite
CREATE TABLE spo_triplets (
    id TEXT PRIMARY KEY,
    subject TEXT NOT NULL,
    predicate TEXT NOT NULL,
    object TEXT NOT NULL,
    confidence REAL,
    tier TEXT CHECK(tier IN ('bronze', 'silver', 'gold')),
    provenance_json TEXT,  -- JSON mit source_id, extraction_method, etc.
    created_at TEXT,
    verified_at TEXT
);

CREATE INDEX idx_subject ON spo_triplets(subject);
CREATE INDEX idx_tier ON spo_triplets(tier);
```

**Vorteile:**
- ‚úÖ Portabel (eine Datei)
- ‚úÖ Schnell f√ºr sequentielle MCTS-Prozesse
- ‚úÖ JSON-Support f√ºr flexible Metadata
- ‚úÖ ACID-Transaktionen f√ºr Tier-Promotions

---

### Frage 2: XoT-Simulator Model

**Options:**
- A) Eigenes schnelles LLM (Qwen-2.5-14B / Llama-3-8B)
- B) Gleiches LLM wie ToT (einfacher, aber langsamer)

**Gemini-Entscheidung: Option A (Eigenes 8B/14B Modell)**

**Begr√ºndung:**
> "Die Heuristik (XoT) *muss* deutlich schneller sein als der Denker (ToT), sonst verliert der Effizienz-Vorteil seinen Sinn. Ein 8B oder 14B Modell ist ideal f√ºr 'Bauchgef√ºhl'-Einsch√§tzungen."

**Recommended Models:**
1. **Qwen-2.5-14B-Instruct** (beste Reasoning/Token-Ratio)
2. **Llama-3.1-8B-Instruct** (schnellste Alternative)
3. **Phi-3-Medium-14B** (kompakt, aber gut)

**Implementation:**
```python
# config/models/xot_qwen_llamacpp.json
{
    "model_id": "xot_qwen",
    "provider": "llamacpp",
    "path": "models/qwen2.5-14b-instruct-q4_k_m.gguf",
    "capabilities": ["reasoning"],
    "context_window": 32768,
    "purpose": "xot_simulation",  # ‚Üê Neues purpose-Tag
    "n_gpu_layers": 35,
    "n_ctx": 8192  # XoT braucht weniger Context
}
```

---

### Frage 3: BiasVector Extraction

**Options:**
- A) Manuelle Kalibrierung f√ºr Sources
- B) Automatische LLM-Extraktion

**Gemini-Entscheidung: Option B (Automatische Extraktion)**

**Begr√ºndung:**
> "Die manuelle Kalibrierung f√ºr jede Quelle ist zu aufwendig. Das Modell soll den BiasVector vorschlagen (basierend auf Textanalyse), den du dann im Deep Graph manuell 'festschreiben' oder korrigieren kannst."

**Implementation Flow:**
```
1. LLM analysiert Response/Source
2. BiasVector vorgeschlagen (z.B. risk_affinity: 0.7)
3. User kann akzeptieren/editieren/verwerfen
4. Finaler BiasVector wird im Perspektiven-Graph gespeichert
5. Zuk√ºnftige Responses dieser Source nutzen cached BiasVector
```

**Prompt Template:**
```python
BIAS_EXTRACTION_PROMPT = """
Analyze the following text and extract a BiasVector with these dimensions:

1. risk_affinity: -1.0 (risk-averse) to +1.0 (risk-seeking)
2. time_horizon: -1.0 (short-term) to +1.0 (long-term)
3. centralization: -1.0 (decentralized) to +1.0 (centralized)
4. empirical_depth: 0.0 (anecdotal) to 1.0 (data-driven)
5. profit_motive: 0.0 (neutral) to 1.0 (commercial agenda)

Text: {response_text}

Respond with ONLY JSON:
{{
    "risk_affinity": 0.5,
    "time_horizon": 0.3,
    ...
}}
"""
```

---

### Frage 4: RLM Priority

**Options:**
- A) Kritisch (ohne RLM kein 10M+ Context)
- B) Optional (128k reicht f√ºr die meisten Use Cases)

**Gemini-Entscheidung: Option A (HOCH - Kritisch)**

**Begr√ºndung:**
> "Wenn du Reddit-Threads mit 50.000 Kommentaren nach 'echter Erfahrung' scannen willst, reicht ein 128k Fenster nicht aus. F√ºr echte 'Sovereign Research' ist die Tiefe (10M+ Context) der entscheidende Vorteil gegen√ºber Standard-Tools."

**Use Cases die RLM brauchen:**
- ‚úÖ Reddit Validation (50k+ Kommentare)
- ‚úÖ PDF-Sammlung Analyse (100+ Papers)
- ‚úÖ Multi-Source Verification (20+ Quellen vergleichen)
- ‚úÖ Historische Datenanalyse (Jahre an Logs/Berichten)

**Neue Priorit√§t:** Cluster 4 (nach BiasVector, weil BiasVector f√ºr Source-Profiling bei RLM wichtig ist)

---

### Frage 5: Privacy Priority

**Options:**
- A) Kritisch (auch lokal keine Axiome/Prompts loggen)
- B) Optional (nur bei Cloud-Nutzung relevant)

**Gemini-Entscheidung: Option B (Fokus auf Cloud-Sanitization)**

**Begr√ºndung:**
> "Solange du 100% lokal arbeitest, ist die interne Maskierung zweitrangig. Sie wird erst kritisch, wenn du Cloud-Modelle (wie Claude 4) als 'Workers' einsetzt."

**Implementation Plan:**
- Cluster 5 bleibt optional
- Nur implementieren wenn Cloud-APIs genutzt werden
- Fokus: Sanitization vor Cloud-Call (nicht f√ºr lokale Logs)

---

## 3. Finale Implementation Roadmap

### ‚úÖ Cluster 1: Foundations (Woche 1-2)
**Priorit√§t:** KRITISCH

**Komponenten:**
1. ‚úÖ **SPOExtractor** (`src/core/spo_extractor.py`)
   - Strukturierte Triplett-Extraktion aus LLM-Responses
   - Subject-Predicate-Object Parsing
   - Provenance Tracking
   - SQLite Integration

2. ‚úÖ **XoTSimulator** (`src/core/xot_simulator.py`)
   - Schnelle Heuristik vor MCTS-Selection
   - Eigenes 8B/14B Modell (Qwen-2.5-14B)
   - Prior Probability Estimation

3. ‚úÖ **TokenBudgetManager** (`src/core/token_budget_manager.py`)
   - Node-spezifisches Token-Limit
   - Dynamische Budget-Zuteilung
   - Automatisches Pruning

4. ‚ö†Ô∏è **GraphManager SPO-Extension** (bestehende Datei erweitern)
   - SPO-Methoden hinzuf√ºgen (parallel zu Legacy)
   - SQLite Backend Integration
   - Migration Helper f√ºr alte Nodes

**Deliverables:**
- SPO-Tripletts werden extrahiert und in SQLite gespeichert
- MCTS nutzt XoT f√ºr Prior-Sch√§tzungen
- Token-Budget verhindert Ewigkeitsschleifen

---

### ‚úÖ Cluster 2: Verified Knowledge (Woche 3-4)
**Priorit√§t:** HOCH

**Komponenten:**
1. ‚úÖ **TieredRAG** (`src/core/tiered_rag.py`)
   - Bronze Tier: Raw SPO-Tripletts
   - Silver Tier: Provenance-tracked Tripletts
   - Gold Tier: Multi-Source verifizierte Tripletts
   - Promotion/Demotion Workflow

2. ‚úÖ **AxiomJudge** (`src/core/axiom_judge.py`)
   - LLM-based Axiom Evaluation
   - RLAIF Feedback Loop
   - Explanation Generation

3. ‚úÖ **ConflictResolver** (`src/core/conflict_resolver.py`)
   - Axiom-Hierarchie (priority: critical > high > medium)
   - Tie-Breaker Logic f√ºr MCTS
   - Conflict Detection in SPO-Graph

4. ‚ö†Ô∏è **AxiomManager Extension**
   - RLAIF Integration
   - Dynamische Weight Adjustment
   - Conflict Resolution Interface

**Deliverables:**
- 3-Tier Knowledge Graph funktioniert
- Axiome werden durch LLM evaluiert mit Erkl√§rungen
- MCTS kann Pfad-Konflikte aufl√∂sen

---

### ‚úÖ Cluster 3: Perspectives (Woche 5-6)
**Priorit√§t:** MITTEL

**Komponenten:**
1. ‚úÖ **BiasVectorExtractor** (`src/core/bias_vector_extractor.py`)
   - Automatische Bias-Analyse via LLM
   - User-Korrektur-Interface
   - Caching f√ºr bekannte Sources

2. ‚úÖ **PerspectiveGraph** (`src/core/perspective_graph.py`)
   - Separater Graph f√ºr Bias-Tracking
   - Bias-Distance Calculation
   - Source Profiling

3. ‚ö†Ô∏è **DebateManager Extension**
   - BiasVector Integration in Arguments
   - Contrastive Debate zwischen Sources mit verschiedenen BiasVectors
   - Perspective-Aware Verdict

**Deliverables:**
- BiasVector wird f√ºr alle Responses extrahiert
- Perspektiven-Graph zeigt Source-Landschaft
- Debates ber√ºcksichtigen Bias-Distanz

---

### ‚úÖ Cluster 4: Deep Intelligence (Woche 7-8)
**Priorit√§t:** HOCH (RLM), MITTEL (Epistemic MCTS)

**Komponenten:**
1. ‚úÖ **RLMEnvironment** (`src/core/rlm_environment.py`)
   - Python REPL Environment
   - Code Execution Sandbox
   - Prompt-as-Environment Architektur
   - CEO-Worker Pattern

2. ‚úÖ **EpistemicMCTS** (`src/core/epistemic_mcts.py`)
   - Value of Information (VoI) Calculation
   - Dynamic Scraping Queue
   - Cost/Benefit Analysis
   - Stopping Criteria

3. ‚ö†Ô∏è **CoverageAnalyzer Extension**
   - VoI Integration
   - Uncertainty Modeling
   - Information Gain Estimation

**Deliverables:**
- 10M+ Token Context via RLM
- MCTS entscheidet intelligent, wo weitere Recherche lohnt
- VoI-basierte Priorisierung

---

### ‚ö†Ô∏è Cluster 5: Hardening (Woche 9-10, Optional)
**Priorit√§t:** NIEDRIG (nur bei Cloud-Nutzung)

**Komponenten:**
1. ‚ö†Ô∏è **PrivacySanitizer** (`src/core/privacy_sanitizer.py`)
   - Metadata Masking vor Cloud-Calls
   - Axiom-Anonymisierung
   - Audit Logging

2. ‚ö†Ô∏è **RedditValidator** (`src/core/reddit_validator.py`)
   - Reddit API (PRAW) Integration
   - Experience-Node Extraction
   - Human Consensus Scoring
   - Friction-Check

**Deliverables:**
- Privacy-geh√§rtetes System bei Cloud-Nutzung
- Social Validation Layer (optional)

---

## 4. Geminis Finale Empfehlung

**Gemini-Zitat:**
> "Ich bin bereit! Du kannst nun Claude Code den Befehl geben, mit **Cluster 1** zu starten, wobei wir die **SPO-Extraktion** als erste Aufgabe priorisieren."

**Befehl f√ºr Claude Code:**
```
Gemini hat das Review abgeschlossen. Wir starten mit Cluster 1 (neu priorisiert).

Aufgaben:
1. Implementiere SPOExtractor in src/core/spo_extractor.py
2. SQLite Backend f√ºr SPO-Tripletts (Bronze/Silver/Gold Tiers)
3. XoTSimulator mit eigenem 8B/14B Modell
4. TokenBudgetManager f√ºr MCTS
5. GraphManager um SPO-Methoden erweitern

Design-Entscheidungen (alle beantwortet):
- SPO Storage: SQLite (Option B)
- XoT Model: Eigenes schnelles Modell (Option A)
- BiasVector: Automatische Extraktion (Option B)
- RLM Priority: Kritisch - Cluster 4 (Option A)
- Privacy: Optional - nur bei Cloud (Option B)

Zus√§tzliche Komponenten aus Gemini-Review:
- ConflictResolver (Cluster 2)
- TokenBudgetManager (Cluster 1)
```

---

## 5. Offene Punkte f√ºr Implementation

### Sofort ben√∂tigt (Cluster 1):
- [ ] Modell-Download: Qwen-2.5-14B-Instruct-Q4_K_M (~8GB)
- [ ] SQLite Schema Design f√ºr SPO-Tripletts
- [ ] XoT-Prompt Engineering (sehr kurz, Heuristik-Stil)
- [ ] Token-Budget Strategie (Gesamt-Budget? Node-Budget-Formula?)

### Sp√§ter ben√∂tigt (Cluster 2+):
- [ ] Axiom-Hierarchie definieren (priority: critical vs. high)
- [ ] BiasVector-Extraction Prompt Engineering
- [ ] RLM-Sandbox Security (welcher Python-Executor?)

---

**Status:** ‚úÖ Review Complete - Ready for Implementation

**N√§chster Schritt:** Dokumentation aufr√§umen, dann Cluster 1 starten.
